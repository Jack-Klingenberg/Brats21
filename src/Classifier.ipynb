{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVFDz655fekb",
        "outputId": "d4d6d20e-2ccb-496a-e56b-9c6b01bdde02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYekcttD5BzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow \n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import random"
      ],
      "metadata": {
        "id": "lR4JatXjfsnk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/gdrive/MyDrive/BraTSProject/data/BraTS2021_Training_Data\""
      ],
      "metadata": {
        "id": "b72MJAQYgHxo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(nib.load(train_data_path+\"/BraTS2021_00000/BraTS2021_00000_flair.nii.gz\")):\n",
        "  image_size=nib.load(train_data_path+\"/BraTS2021_00000/BraTS2021_00000_flair.nii.gz\").get_fdata().shape[0]\n",
        "  print(\"Data path working...\")\n",
        "  print(image_size)\n",
        "else:\n",
        "  print(\"Data path failed. Make sure your data_path is correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZKrsi78gvOj",
        "outputId": "6dfc39ec-ae8f-456d-e038-7906a39721c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data path working...\n",
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATA_PATH = \"/content/gdrive/MyDrive/BraTSProject/data/BraTS2021_Training_Data\"\n",
        "TRANSLATED_4PATH = \"/content/gdrive/MyDrive/BraTSProject/Classifier/4classification.pickle\"\n",
        "FRONT_LEFT  = [1, 0, 0, 0]\n",
        "FRONT_RIGHT = [0, 1, 0, 0]\n",
        "BACK_LEFT   = [0, 0, 1, 0]\n",
        "BACK_RIGHT  = [0, 0, 0, 1]\n",
        "\n",
        "\n",
        "def load_image(path, downsampling_factor=1):\n",
        "    volume = nib.load(path).get_fdata()\n",
        "    if downsampling_factor != 1:\n",
        "        new_shape = np.array(volume.shape) // downsampling_factor\n",
        "        volume = zoom(volume, new_shape / np.array(volume.shape), order=3)\n",
        "    return volume\n",
        "\n",
        "def load_image_paths():\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if('flair.nii' in file):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "    return image_paths\n",
        "\n",
        "def load_segmentation_paths():\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if('seg.nii' in file):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "    return image_paths\n",
        "\n",
        "def load_images():\n",
        "    images = []\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if('flair.nii' in file):\n",
        "                images.append(load_image(os.path.join(root, file)))\n",
        "    return images\n",
        "\n",
        "def load_segmentations():\n",
        "    segmentations = []\n",
        "    for root, dirs, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if('seg.nii' in file):\n",
        "                segmentations.append(load_image(os.path.join(root, file)))\n",
        "    return segmentations\n",
        "\n",
        "def load_classifications():\n",
        "    return pickle.load(TRANSLATED_4PATH)\n",
        "\n",
        "# Translate a label and image from a segmentation to the region where the tumor is.\n",
        "def translate_label(image, label):\n",
        "    tumor_indices = np.argwhere(label > 0)\n",
        "    brain_indices = np.argwhere(image > 0)\n",
        "    tumor_center_of_mass = tumor_indices.mean(axis=0)\n",
        "    brain_center_of_mass = brain_indices.mean(axis=0)\n",
        "    if(tumor_center_of_mass[1] < brain_center_of_mass[1]):\n",
        "        if(tumor_center_of_mass[2] < brain_center_of_mass[2]):\n",
        "            return FRONT_LEFT\n",
        "        else:\n",
        "            return BACK_LEFT\n",
        "    else:\n",
        "        if(tumor_center_of_mass[2] < brain_center_of_mass[2]):\n",
        "            return FRONT_RIGHT\n",
        "        else:\n",
        "            return BACK_RIGHT\n",
        "\n",
        "def save_4classification():\n",
        "    img_paths = load_image_paths()\n",
        "    label_paths = load_segmentation_paths()\n",
        "    N_IMGS = len(img_paths)\n",
        "    translated = []\n",
        "    for i in range(N_IMGS):\n",
        "        img = load_image(img_paths[i])\n",
        "        lbl = load_image(label_paths[i])\n",
        "        t_lbl = translate_label(img, lbl)\n",
        "        translated.append(t_lbl)\n",
        "    with open(TRANSLATED_4PATH, 'wb') as f:\n",
        "        pickle.dump(translated, f)\n",
        "\n",
        "def load_4classification():\n",
        "    labels = None\n",
        "    with open(TRANSLATED_4PATH, 'rb') as f:\n",
        "        labels = pickle.load(f)\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "5pXEHIiZwwtM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_labels = load_4classification()\n",
        "\n",
        "print(f\"FRONT LEFT {classification_labels.count(FRONT_LEFT)}\")\n",
        "print(f\"FRONT RIGHT {classification_labels.count(FRONT_RIGHT)}\")\n",
        "print(f\"FRONT LEFT {classification_labels.count(BACK_LEFT)}\")\n",
        "print(f\"BACK RIGHT {classification_labels.count(BACK_RIGHT)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCs5Lz8D-rHk",
        "outputId": "c118305d-75f1-415e-a201-60276c4f9e23"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FRONT LEFT 301\n",
            "FRONT RIGHT 215\n",
            "FRONT LEFT 378\n",
            "BACK RIGHT 357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import rotate\n",
        "from tensorflow.keras.utils import Sequence\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_paths, labels, batch_size):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size // 2 # adjusting for later insertion of augmented images\n",
        "        self.image_shape = load_image(self.image_paths[0]).shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_image_paths = self.image_paths[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        blabels = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = np.zeros((2 * self.batch_size, *self.image_shape))  # Double the size to include original and augmented images\n",
        "        batch_labels = np.zeros((2 * self.batch_size, 4))\n",
        "\n",
        "        for i, image_path in enumerate(batch_image_paths):\n",
        "            original_image = load_image(image_path, downsampling_factor=2)\n",
        "            augmented_image = self.augment_image(np.copy(original_image))\n",
        "\n",
        "            batch_images[2 * i] = original_image\n",
        "            batch_images[2 * i + 1] = augmented_image\n",
        "            batch_labels[2 * i] = blabels[i]\n",
        "            batch_labels[2 * i + 1] = blabels[i]\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def augment_image(self, image):\n",
        "        # Flip\n",
        "        if random.random() < 0.5:\n",
        "            image = np.flip(image, axis=random.choice([0, 1]))\n",
        "\n",
        "        # Rotate\n",
        "        angle = random.uniform(-20, 20)\n",
        "        axes = random.choice([(0, 1), (1, 2), (0, 2)])\n",
        "        image = rotate(image, angle, axes=axes, reshape=False, mode='nearest')\n",
        "\n",
        "        # Adjust brightness\n",
        "        brightness_factor = random.uniform(0.8, 1.2)\n",
        "        image = np.clip(image * brightness_factor, 0, 255)\n",
        "\n",
        "        return image[:, :, :, 64]"
      ],
      "metadata": {
        "id": "dEGq6_4K00zJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv3D(16, (3, 3, 3), activation='relu', input_shape=(240, 240, 64, 1)))\n",
        "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
        "    model.add(layers.Conv3D(32, (3, 3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
        "    model.add(layers.Conv3D(32, (3, 3, 3), activation='relu'))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    image_paths = load_image_paths()\n",
        "    labels = np.array(load_4classification())\n",
        "\n",
        "    N_IMAGES = len(image_paths)\n",
        "    N_TRAIN = (N_IMAGES // 4)\n",
        "\n",
        "    train_image_paths, test_image_paths = image_paths[:N_TRAIN], image_paths[N_TRAIN:]\n",
        "    train_labels, test_labels = labels[:N_TRAIN], labels[N_TRAIN:]\n",
        "\n",
        "\n",
        "    \n",
        "    # Test using less then the whole dataset\n",
        "    '''\n",
        "    train_image_paths = train_image_paths[:(len(train_image_paths) // 4)]\n",
        "    test_image_paths = test_image_paths[:(len(test_image_paths) // 4)]\n",
        "    train_labels = train_labels[:(len(train_labels) // 4)]\n",
        "    test_labels = test_labels[:(len(test_labels) // 4)]\n",
        "    '''\n",
        "\n",
        "    train_generator = DataGenerator(train_image_paths, train_labels, 3)\n",
        "    test_generator = DataGenerator(test_image_paths, test_labels, 3)\n",
        "\n",
        "    model = create_model()\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_generator, epochs=5, validation_data=test_generator)\n",
        "    model.save('/content/gdrive/MyDrive/BraTSProject/Classifier')\n",
        "    test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
        "    print('Test accuracy:', test_acc)\n",
        "\n"
      ],
      "metadata": {
        "id": "gg0URzz4wsG0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "DpISppTdxi1a",
        "outputId": "4aa7c6e4-d053-415e-a26c-50266d491ce9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-e2048c93d6aa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/BraTSProject/Classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-c3e17a72ed0e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampling_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0maugmented_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-5e0faf964702>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path, downsampling_factor)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdownsampling_factor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mdownsampling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzoom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_shape\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'zoom' is not defined"
          ]
        }
      ]
    }
  ]
}